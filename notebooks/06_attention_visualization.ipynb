{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a074cfa",
   "metadata": {},
   "source": [
    "# 06 - Attention Visualization and Model Explainability\n",
    "\n",
    "This notebook provides explainability for our CodeBERT vulnerability detection model through attention visualization.\n",
    "\n",
    "**Objectives:**\n",
    "- Extract attention weights from the trained model\n",
    "- Map attention to source code tokens and lines\n",
    "- Generate highlighted HTML visualizations\n",
    "- Create attention heatmaps for different vulnerability types\n",
    "- Analyze which code patterns the model focuses on\n",
    "\n",
    "**Outputs:**\n",
    "- `results/visualizations/attention_*.html` - Interactive attention visualizations\n",
    "- `results/visualizations/attention_heatmaps.png` - Attention pattern analysis\n",
    "- `results/visualizations/token_importance.csv` - Token-level importance scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f81af83",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a0d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import re\n",
    "\n",
    "# HTML and visualization\n",
    "from IPython.display import HTML, display\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Transformers and ML\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00421dbb",
   "metadata": {},
   "source": [
    "## Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5ff171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BASE_DIR = Path('/home/netweb/vasu/smart-contract-vuln-detector')\n",
    "DATA_DIR = BASE_DIR / 'data/processed'\n",
    "RESULTS_DIR = BASE_DIR / 'results'\n",
    "MODELS_DIR = BASE_DIR / 'models'\n",
    "\n",
    "# Create directories\n",
    "(RESULTS_DIR / 'visualizations').mkdir(exist_ok=True)\n",
    "\n",
    "# Model configuration\n",
    "MODEL_NAME = \"microsoft/codebert-base\"\n",
    "MAX_LENGTH = 512\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Attention visualization settings\n",
    "ATTENTION_HEAD_AVERAGE = True  # Average across attention heads\n",
    "LAYER_TO_USE = -1  # Use last layer (-1) or specify layer index\n",
    "TOP_K_TOKENS = 20  # Number of top tokens to highlight\n",
    "MIN_ATTENTION_THRESHOLD = 0.01  # Minimum attention score to consider\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Results directory: {RESULTS_DIR}\")\n",
    "print(f\"Attention configuration:\")\n",
    "print(f\"  - Average heads: {ATTENTION_HEAD_AVERAGE}\")\n",
    "print(f\"  - Layer: {LAYER_TO_USE}\")\n",
    "print(f\"  - Top-K tokens: {TOP_K_TOKENS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9fd116",
   "metadata": {},
   "source": [
    "## Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c29d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "print(\"Loading processed datasets...\")\n",
    "test_df = pd.read_csv(DATA_DIR / 'test_functions.csv')\n",
    "\n",
    "# Load label encoder\n",
    "with open(DATA_DIR / 'label_encoder.pkl', 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "print(f\"Test set: {len(test_df)} samples\")\n",
    "print(f\"Classes: {list(label_encoder.classes_)}\")\n",
    "\n",
    "# Show test set distribution\n",
    "print(\"\\nTest set distribution:\")\n",
    "for label, count in test_df['labels'].value_counts().sort_index().items():\n",
    "    print(f\"  {label}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1812a894",
   "metadata": {},
   "source": [
    "## Define Enhanced Model with Attention Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4db56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeBERTClassifierWithAttention(nn.Module):\n",
    "    def __init__(self, model_name: str, num_classes: int, dropout_rate: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.codebert = AutoModel.from_pretrained(model_name)\n",
    "        \n",
    "        # Classification head\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.classifier = nn.Linear(self.codebert.config.hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, return_attention=False):\n",
    "        outputs = self.codebert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_attentions=True  # Always output attentions for visualization\n",
    "        )\n",
    "        \n",
    "        # Use [CLS] token representation\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]  # [CLS] token\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        result = {\n",
    "            'logits': logits,\n",
    "            'attentions': outputs.attentions,\n",
    "            'last_hidden_state': outputs.last_hidden_state\n",
    "        }\n",
    "            \n",
    "        return result\n",
    "\n",
    "# Dataset class with source code preservation\n",
    "class VulnDatasetWithSource(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        # Tokenize the source code\n",
    "        encoding = self.tokenizer(\n",
    "            row['source_code'],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'label': torch.tensor(row['label_encoded'], dtype=torch.long),\n",
    "            'contract_id': row['contract_id'],\n",
    "            'function_id': row['function_id'],\n",
    "            'original_label': row['labels'],\n",
    "            'source_code': row['source_code']\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Enhanced model with attention extraction defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8625ed49",
   "metadata": {},
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba46bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and load the best model\n",
    "checkpoint_files = list((RESULTS_DIR / 'checkpoints').glob('best_model_*.pt'))\n",
    "model_files = list(MODELS_DIR.glob('*.pt'))\n",
    "\n",
    "if checkpoint_files:\n",
    "    model_path = checkpoint_files[0]\n",
    "    print(f\"Loading checkpoint: {model_path.name}\")\n",
    "elif model_files:\n",
    "    model_path = model_files[0]\n",
    "    print(f\"Loading model: {model_path.name}\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"No trained model found!\")\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "print(\"Loading tokenizer and model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CodeBERTClassifierWithAttention(MODEL_NAME, num_classes)\n",
    "\n",
    "# Load weights\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "if 'model_state_dict' in checkpoint:\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"‚úÖ Loaded checkpoint from step {checkpoint.get('step', 'unknown')}\")\n",
    "else:\n",
    "    model.load_state_dict(checkpoint)\n",
    "    print(\"‚úÖ Loaded model weights\")\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print(f\"Model loaded on: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00f62c0",
   "metadata": {},
   "source": [
    "## Select Representative Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22bb823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select representative examples for visualization\n",
    "def select_representative_examples(df, label_encoder, n_per_class=2):\n",
    "    \"\"\"Select representative examples for each vulnerability type.\"\"\"\n",
    "    selected_examples = []\n",
    "    \n",
    "    for class_name in label_encoder.classes_:\n",
    "        class_samples = df[df['labels'] == class_name]\n",
    "        \n",
    "        if len(class_samples) > 0:\n",
    "            # Select samples with varying source code lengths for diversity\n",
    "            class_samples = class_samples.copy()\n",
    "            class_samples['code_length'] = class_samples['source_code'].str.len()\n",
    "            \n",
    "            # Select samples: shortest, longest, and random ones in between\n",
    "            if len(class_samples) >= n_per_class:\n",
    "                sorted_samples = class_samples.sort_values('code_length')\n",
    "                indices = np.linspace(0, len(sorted_samples)-1, n_per_class, dtype=int)\n",
    "                selected = sorted_samples.iloc[indices]\n",
    "            else:\n",
    "                selected = class_samples.head(n_per_class)\n",
    "            \n",
    "            selected_examples.extend(selected.index.tolist())\n",
    "            \n",
    "            print(f\"Selected {len(selected)} examples for class '{class_name}'\")\n",
    "            for _, row in selected.iterrows():\n",
    "                print(f\"  - {row['contract_id']}:{row['function_id']} (length: {len(row['source_code'])} chars)\")\n",
    "    \n",
    "    return selected_examples\n",
    "\n",
    "# Select examples\n",
    "print(\"Selecting representative examples for visualization...\")\n",
    "selected_indices = select_representative_examples(test_df, label_encoder, n_per_class=1)\n",
    "\n",
    "# Create subset dataset\n",
    "visualization_df = test_df.iloc[selected_indices].reset_index(drop=True)\n",
    "visualization_dataset = VulnDatasetWithSource(visualization_df, tokenizer, MAX_LENGTH)\n",
    "\n",
    "print(f\"\\nüìä Selected {len(visualization_df)} examples for visualization\")\n",
    "print(f\"Distribution: {dict(visualization_df['labels'].value_counts())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68de2fd1",
   "metadata": {},
   "source": [
    "## Attention Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b0e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attention_weights(model, input_ids, attention_mask, layer_idx=-1, average_heads=True):\n",
    "    \"\"\"Extract attention weights from the model.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask, return_attention=True)\n",
    "        attentions = outputs['attentions']  # Tuple of attention tensors\n",
    "        \n",
    "        # Select layer\n",
    "        if layer_idx == -1:\n",
    "            attention = attentions[-1]  # Last layer\n",
    "        else:\n",
    "            attention = attentions[layer_idx]\n",
    "        \n",
    "        # attention shape: [batch_size, num_heads, seq_len, seq_len]\n",
    "        if average_heads:\n",
    "            attention = attention.mean(dim=1)  # Average across heads\n",
    "        \n",
    "        return attention, outputs['logits']\n",
    "\n",
    "def get_token_importance(attention_weights, attention_mask, method='cls_attention'):\n",
    "    \"\"\"Calculate token importance from attention weights.\"\"\"\n",
    "    # attention_weights: [seq_len, seq_len] or [num_heads, seq_len, seq_len]\n",
    "    if attention_weights.dim() == 3:\n",
    "        attention_weights = attention_weights.mean(dim=0)  # Average heads if needed\n",
    "    \n",
    "    if method == 'cls_attention':\n",
    "        # Use attention from CLS token (first token) to all other tokens\n",
    "        token_importance = attention_weights[0, :]  # CLS attention to all tokens\n",
    "    elif method == 'sum_attention':\n",
    "        # Sum of attention weights for each token (as target)\n",
    "        token_importance = attention_weights.sum(dim=0)\n",
    "    elif method == 'mean_attention':\n",
    "        # Mean attention for each token\n",
    "        token_importance = attention_weights.mean(dim=0)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    # Apply attention mask (set padded tokens to 0)\n",
    "    token_importance = token_importance * attention_mask.float()\n",
    "    \n",
    "    return token_importance\n",
    "\n",
    "def map_tokens_to_source(tokenizer, input_ids, source_code):\n",
    "    \"\"\"Map tokenizer tokens back to source code positions.\"\"\"\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    \n",
    "    # Remove special tokens and convert back to text\n",
    "    decoded_tokens = []\n",
    "    token_positions = []\n",
    "    \n",
    "    current_pos = 0\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in ['<s>', '</s>', '<pad>', '<unk>']:\n",
    "            decoded_tokens.append(token)\n",
    "            token_positions.append(-1)  # Special token\n",
    "        else:\n",
    "            # Convert RoBERTa token back to text\n",
    "            token_text = token.replace('ƒ†', ' ').replace('ƒä', '\\n')\n",
    "            \n",
    "            # Find position in source code\n",
    "            if current_pos < len(source_code):\n",
    "                # Simple position tracking (this is a simplification)\n",
    "                pos = source_code.find(token_text.strip(), current_pos)\n",
    "                if pos != -1:\n",
    "                    token_positions.append(pos)\n",
    "                    current_pos = pos + len(token_text.strip())\n",
    "                else:\n",
    "                    token_positions.append(current_pos)\n",
    "            else:\n",
    "                token_positions.append(-1)\n",
    "            \n",
    "            decoded_tokens.append(token_text)\n",
    "    \n",
    "    return tokens, decoded_tokens, token_positions\n",
    "\n",
    "print(\"‚úÖ Attention extraction functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb57705",
   "metadata": {},
   "source": [
    "## Generate Attention Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c6da3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_attention_html(tokens, attention_scores, source_code, prediction, true_label, \n",
    "                         contract_id, function_id, confidence, top_k=20):\n",
    "    \"\"\"Create HTML visualization of attention weights.\"\"\"\n",
    "    \n",
    "    # Normalize attention scores\n",
    "    max_attention = attention_scores.max().item() if attention_scores.max() > 0 else 1\n",
    "    normalized_attention = attention_scores / max_attention\n",
    "    \n",
    "    # Get top-k most attended tokens\n",
    "    top_indices = attention_scores.argsort(descending=True)[:top_k]\n",
    "    \n",
    "    # Create HTML\n",
    "    html_content = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Attention Visualization - {contract_id}:{function_id}</title>\n",
    "        <style>\n",
    "            body {{ font-family: 'Courier New', monospace; margin: 20px; background-color: #f8f9fa; }}\n",
    "            .header {{ background-color: #343a40; color: white; padding: 15px; border-radius: 5px; margin-bottom: 20px; }}\n",
    "            .info {{ background-color: #e9ecef; padding: 10px; border-radius: 5px; margin-bottom: 15px; }}\n",
    "            .code-container {{ background-color: white; padding: 20px; border-radius: 5px; border: 1px solid #dee2e6; }}\n",
    "            .token {{ display: inline; padding: 2px; margin: 1px; border-radius: 3px; }}\n",
    "            .legend {{ margin-top: 20px; padding: 15px; background-color: #f8f9fa; border-radius: 5px; }}\n",
    "            .top-tokens {{ margin-top: 15px; }}\n",
    "            .attention-bar {{ width: 100%; height: 20px; background: linear-gradient(to right, #fff, #ff0000); margin-bottom: 10px; }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"header\">\n",
    "            <h2>üîç Attention Visualization</h2>\n",
    "            <p><strong>Contract:</strong> {contract_id} | <strong>Function:</strong> {function_id}</p>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"info\">\n",
    "            <p><strong>üéØ Prediction:</strong> <span style=\"color: {'green' if prediction == true_label else 'red'};\">{prediction}</span></p>\n",
    "            <p><strong>‚úì True Label:</strong> {true_label}</p>\n",
    "            <p><strong>üìä Confidence:</strong> {confidence:.3f}</p>\n",
    "            <p><strong>ü§ñ Model Focus:</strong> Tokens highlighted by attention intensity (red = high attention)</p>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"code-container\">\n",
    "            <h3>üíª Source Code with Attention Highlighting:</h3>\n",
    "            <pre style=\"white-space: pre-wrap; line-height: 1.6;\">\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add tokens with attention highlighting\n",
    "    for i, (token, attention) in enumerate(zip(tokens, normalized_attention)):\n",
    "        if token in ['<s>', '</s>', '<pad>']:\n",
    "            continue\n",
    "            \n",
    "        # Calculate color intensity based on attention\n",
    "        intensity = attention.item()\n",
    "        \n",
    "        if intensity > 0.1:  # Only highlight significant attention\n",
    "            # Convert to RGB color (white to red gradient)\n",
    "            red = min(255, int(255 * intensity))\n",
    "            green = max(0, int(255 * (1 - intensity)))\n",
    "            blue = max(0, int(255 * (1 - intensity)))\n",
    "            \n",
    "            color = f\"rgb({red}, {green}, {blue})\"\n",
    "            html_content += f'<span class=\"token\" style=\"background-color: {color}; color: white;\">{token.replace(\"ƒ†\", \" \").replace(\"ƒä\", \"<br>\")}</span>'\n",
    "        else:\n",
    "            html_content += token.replace('ƒ†', ' ').replace('ƒä', '<br>')\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "            </pre>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"legend\">\n",
    "            <h3>üé® Attention Legend:</h3>\n",
    "            <div class=\"attention-bar\"></div>\n",
    "            <p><strong>Low Attention</strong> ‚Üê ‚Üí <strong>High Attention</strong></p>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add top attended tokens\n",
    "    html_content += '<div class=\"top-tokens\"><h4>üî• Top Attended Tokens:</h4><ol>'\n",
    "    \n",
    "    for idx in top_indices[:10]:  # Show top 10\n",
    "        token = tokens[idx]\n",
    "        score = attention_scores[idx].item()\n",
    "        if token not in ['<s>', '</s>', '<pad>'] and score > 0.01:\n",
    "            clean_token = token.replace('ƒ†', ' ').replace('ƒä', '\\\\n')\n",
    "            html_content += f'<li><code>{clean_token}</code> (attention: {score:.4f})</li>'\n",
    "    \n",
    "    html_content += \"\"\"\n",
    "            </ol>\n",
    "        </div>\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    \n",
    "    return html_content\n",
    "\n",
    "# Process examples and generate visualizations\n",
    "print(\"Generating attention visualizations...\")\n",
    "\n",
    "attention_results = []\n",
    "visualization_files = []\n",
    "\n",
    "for idx in tqdm(range(len(visualization_dataset)), desc=\"Processing examples\"):\n",
    "    example = visualization_dataset[idx]\n",
    "    \n",
    "    # Prepare inputs\n",
    "    input_ids = example['input_ids'].unsqueeze(0).to(device)\n",
    "    attention_mask = example['attention_mask'].unsqueeze(0).to(device)\n",
    "    \n",
    "    # Extract attention\n",
    "    attention_weights, logits = extract_attention_weights(\n",
    "        model, input_ids, attention_mask, \n",
    "        layer_idx=LAYER_TO_USE, \n",
    "        average_heads=ATTENTION_HEAD_AVERAGE\n",
    "    )\n",
    "    \n",
    "    # Get token importance\n",
    "    token_importance = get_token_importance(\n",
    "        attention_weights[0], example['attention_mask'], \n",
    "        method='cls_attention'\n",
    "    )\n",
    "    \n",
    "    # Get prediction\n",
    "    prediction_idx = torch.argmax(logits, dim=-1).item()\n",
    "    prediction = label_encoder.classes_[prediction_idx]\n",
    "    confidence = torch.softmax(logits, dim=-1).max().item()\n",
    "    \n",
    "    # Map tokens\n",
    "    tokens, decoded_tokens, token_positions = map_tokens_to_source(\n",
    "        tokenizer, example['input_ids'], example['source_code']\n",
    "    )\n",
    "    \n",
    "    # Create HTML visualization\n",
    "    html_content = create_attention_html(\n",
    "        tokens, token_importance, example['source_code'],\n",
    "        prediction, example['original_label'],\n",
    "        example['contract_id'], example['function_id'],\n",
    "        confidence, top_k=TOP_K_TOKENS\n",
    "    )\n",
    "    \n",
    "    # Save HTML file\n",
    "    filename = f\"attention_{example['original_label']}_{example['contract_id']}_{example['function_id']}.html\"\n",
    "    filepath = RESULTS_DIR / 'visualizations' / filename\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    visualization_files.append(str(filepath))\n",
    "    \n",
    "    # Store results for analysis\n",
    "    attention_results.append({\n",
    "        'contract_id': example['contract_id'],\n",
    "        'function_id': example['function_id'],\n",
    "        'true_label': example['original_label'],\n",
    "        'predicted_label': prediction,\n",
    "        'confidence': confidence,\n",
    "        'correct': prediction == example['original_label'],\n",
    "        'attention_scores': token_importance.cpu().numpy(),\n",
    "        'tokens': tokens,\n",
    "        'source_code': example['source_code'],\n",
    "        'html_file': str(filepath)\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úÖ Generated: {filename}\")\n",
    "    print(f\"   True: {example['original_label']} | Pred: {prediction} | Conf: {confidence:.3f}\")\n",
    "\n",
    "print(f\"\\nüéâ Generated {len(visualization_files)} attention visualizations!\")\n",
    "print(f\"üìÅ Saved to: {RESULTS_DIR / 'visualizations'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686a6293",
   "metadata": {},
   "source": [
    "## Attention Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58220827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze attention patterns across vulnerability types\n",
    "print(\"Analyzing attention patterns...\")\n",
    "\n",
    "# Create attention analysis dataframe\n",
    "attention_analysis = []\n",
    "\n",
    "for result in attention_results:\n",
    "    attention_scores = result['attention_scores']\n",
    "    tokens = result['tokens']\n",
    "    \n",
    "    # Skip special tokens and calculate statistics\n",
    "    valid_mask = np.array([token not in ['<s>', '</s>', '<pad>'] for token in tokens])\n",
    "    valid_attention = attention_scores[valid_mask]\n",
    "    \n",
    "    if len(valid_attention) > 0:\n",
    "        attention_analysis.append({\n",
    "            'vulnerability_type': result['true_label'],\n",
    "            'prediction_correct': result['correct'],\n",
    "            'max_attention': valid_attention.max(),\n",
    "            'mean_attention': valid_attention.mean(),\n",
    "            'std_attention': valid_attention.std(),\n",
    "            'attention_entropy': -np.sum(valid_attention * np.log(valid_attention + 1e-8)),\n",
    "            'top_10_attention_sum': np.sort(valid_attention)[-10:].sum(),\n",
    "            'num_high_attention_tokens': np.sum(valid_attention > 0.05),\n",
    "            'contract_id': result['contract_id'],\n",
    "            'function_id': result['function_id']\n",
    "        })\n",
    "\n",
    "attention_df = pd.DataFrame(attention_analysis)\n",
    "\n",
    "print(f\"üìä Attention Analysis Summary:\")\n",
    "print(f\"Total examples analyzed: {len(attention_df)}\")\n",
    "print(f\"\\nBy vulnerability type:\")\n",
    "summary_stats = attention_df.groupby('vulnerability_type').agg({\n",
    "    'max_attention': ['mean', 'std'],\n",
    "    'attention_entropy': ['mean', 'std'],\n",
    "    'num_high_attention_tokens': ['mean', 'std'],\n",
    "    'prediction_correct': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "print(summary_stats)\n",
    "\n",
    "# Create attention pattern visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Max attention by vulnerability type\n",
    "attention_df.boxplot(column='max_attention', by='vulnerability_type', ax=axes[0,0])\n",
    "axes[0,0].set_title('Maximum Attention Score by Vulnerability Type')\n",
    "axes[0,0].set_xlabel('Vulnerability Type')\n",
    "axes[0,0].set_ylabel('Max Attention Score')\n",
    "\n",
    "# 2. Attention entropy by vulnerability type  \n",
    "attention_df.boxplot(column='attention_entropy', by='vulnerability_type', ax=axes[0,1])\n",
    "axes[0,1].set_title('Attention Entropy by Vulnerability Type')\n",
    "axes[0,1].set_xlabel('Vulnerability Type')\n",
    "axes[0,1].set_ylabel('Attention Entropy')\n",
    "\n",
    "# 3. Number of high attention tokens\n",
    "attention_df.boxplot(column='num_high_attention_tokens', by='vulnerability_type', ax=axes[1,0])\n",
    "axes[1,0].set_title('Number of High Attention Tokens by Vulnerability Type')\n",
    "axes[1,0].set_xlabel('Vulnerability Type')\n",
    "axes[1,0].set_ylabel('Number of High Attention Tokens')\n",
    "\n",
    "# 4. Attention vs prediction correctness\n",
    "correct_attention = attention_df[attention_df['prediction_correct']]['max_attention']\n",
    "incorrect_attention = attention_df[~attention_df['prediction_correct']]['max_attention']\n",
    "\n",
    "axes[1,1].hist([correct_attention, incorrect_attention], \n",
    "              label=['Correct Predictions', 'Incorrect Predictions'], \n",
    "              alpha=0.7, bins=15)\n",
    "axes[1,1].set_title('Attention Distribution: Correct vs Incorrect Predictions')\n",
    "axes[1,1].set_xlabel('Max Attention Score')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.suptitle('Attention Pattern Analysis', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save attention analysis plot\n",
    "attention_plot_path = RESULTS_DIR / 'visualizations' / 'attention_patterns_analysis.png'\n",
    "plt.savefig(attention_plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"üíæ Attention analysis plot saved to: {attention_plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509fad4e",
   "metadata": {},
   "source": [
    "## Token Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf5c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze most important tokens across all examples\n",
    "print(\"Analyzing token importance patterns...\")\n",
    "\n",
    "# Collect all token-importance pairs\n",
    "all_token_importance = []\n",
    "\n",
    "for result in attention_results:\n",
    "    tokens = result['tokens']\n",
    "    attention_scores = result['attention_scores']\n",
    "    vulnerability_type = result['true_label']\n",
    "    \n",
    "    for token, score in zip(tokens, attention_scores):\n",
    "        if token not in ['<s>', '</s>', '<pad>'] and score > MIN_ATTENTION_THRESHOLD:\n",
    "            # Clean token for analysis\n",
    "            clean_token = token.replace('ƒ†', '').replace('ƒä', '').strip()\n",
    "            if clean_token:  # Skip empty tokens\n",
    "                all_token_importance.append({\n",
    "                    'token': clean_token.lower(),  # Normalize case\n",
    "                    'raw_token': token,\n",
    "                    'attention_score': float(score),\n",
    "                    'vulnerability_type': vulnerability_type\n",
    "                })\n",
    "\n",
    "token_df = pd.DataFrame(all_token_importance)\n",
    "\n",
    "print(f\"Collected {len(token_df)} token-attention pairs\")\n",
    "\n",
    "# Find most important tokens overall\n",
    "print(\"\\nüî• Most Important Tokens (by average attention):\")\n",
    "top_tokens_overall = token_df.groupby('token').agg({\n",
    "    'attention_score': ['mean', 'count', 'std'],\n",
    "    'vulnerability_type': lambda x: list(set(x))\n",
    "}).round(4)\n",
    "\n",
    "top_tokens_overall.columns = ['avg_attention', 'frequency', 'std_attention', 'vuln_types']\n",
    "top_tokens_overall = top_tokens_overall[top_tokens_overall['frequency'] >= 2]  # At least 2 occurrences\n",
    "top_tokens_overall = top_tokens_overall.sort_values('avg_attention', ascending=False)\n",
    "\n",
    "print(top_tokens_overall.head(20))\n",
    "\n",
    "# Find vulnerability-specific important tokens\n",
    "print(\"\\nüéØ Most Important Tokens by Vulnerability Type:\")\n",
    "for vuln_type in label_encoder.classes_:\n",
    "    vuln_tokens = token_df[token_df['vulnerability_type'] == vuln_type]\n",
    "    if len(vuln_tokens) > 0:\n",
    "        top_vuln_tokens = vuln_tokens.groupby('token').agg({\n",
    "            'attention_score': ['mean', 'count']\n",
    "        })\n",
    "        top_vuln_tokens.columns = ['avg_attention', 'frequency']\n",
    "        top_vuln_tokens = top_vuln_tokens[top_vuln_tokens['frequency'] >= 1]\n",
    "        top_vuln_tokens = top_vuln_tokens.sort_values('avg_attention', ascending=False)\n",
    "        \n",
    "        print(f\"\\n{vuln_type}:\")\n",
    "        print(top_vuln_tokens.head(10))\n",
    "\n",
    "# Save token importance data\n",
    "token_importance_path = RESULTS_DIR / 'visualizations' / 'token_importance_analysis.csv'\n",
    "top_tokens_overall.to_csv(token_importance_path)\n",
    "\n",
    "print(f\"\\nüíæ Token importance analysis saved to: {token_importance_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd8b328",
   "metadata": {},
   "source": [
    "## Create Interactive Attention Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cec89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive attention heatmap using plotly\n",
    "print(\"Creating interactive attention heatmap...\")\n",
    "\n",
    "# Select one example for detailed heatmap (pick the first one with good attention)\n",
    "detailed_example_idx = 0\n",
    "for i, result in enumerate(attention_results):\n",
    "    if result['attention_scores'].max() > 0.1:  # Good attention scores\n",
    "        detailed_example_idx = i\n",
    "        break\n",
    "\n",
    "detailed_example = attention_results[detailed_example_idx]\n",
    "\n",
    "# Get the full attention matrix for this example\n",
    "example_data = visualization_dataset[detailed_example_idx]\n",
    "input_ids = example_data['input_ids'].unsqueeze(0).to(device)\n",
    "attention_mask = example_data['attention_mask'].unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask)\n",
    "    # Get last layer attention without averaging heads\n",
    "    full_attention = outputs['attentions'][-1][0]  # [num_heads, seq_len, seq_len]\n",
    "\n",
    "# Convert to numpy and get relevant tokens\n",
    "attention_matrix = full_attention.cpu().numpy()\n",
    "tokens = detailed_example['tokens']\n",
    "\n",
    "# Find actual sequence length (non-padded)\n",
    "actual_length = int(attention_mask.sum().item())\n",
    "attention_matrix = attention_matrix[:, :actual_length, :actual_length]\n",
    "relevant_tokens = tokens[:actual_length]\n",
    "\n",
    "# Create heatmap for averaged attention\n",
    "avg_attention = attention_matrix.mean(axis=0)  # Average across heads\n",
    "\n",
    "# Clean tokens for display\n",
    "display_tokens = [token.replace('ƒ†', ' ').replace('ƒä', '\\n')[:15] for token in relevant_tokens]\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=avg_attention,\n",
    "    x=display_tokens,\n",
    "    y=display_tokens,\n",
    "    colorscale='Reds',\n",
    "    hoverongaps=False,\n",
    "    hovertemplate='From: %{y}<br>To: %{x}<br>Attention: %{z:.4f}<extra></extra>'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Attention Heatmap - {detailed_example[\"true_label\"]} ({detailed_example[\"contract_id\"]}:{detailed_example[\"function_id\"]})',\n",
    "    xaxis_title='Target Tokens',\n",
    "    yaxis_title='Source Tokens',\n",
    "    width=800,\n",
    "    height=800\n",
    ")\n",
    "\n",
    "# Save interactive heatmap\n",
    "heatmap_path = RESULTS_DIR / 'visualizations' / f'attention_heatmap_{detailed_example[\"true_label\"]}_{detailed_example[\"contract_id\"]}_{detailed_example[\"function_id\"]}.html'\n",
    "fig.write_html(str(heatmap_path))\n",
    "\n",
    "# Show in notebook\n",
    "fig.show()\n",
    "\n",
    "print(f\"üíæ Interactive attention heatmap saved to: {heatmap_path}\")\n",
    "print(f\"üìä Showing attention for: {detailed_example['true_label']} example\")\n",
    "print(f\"   Contract: {detailed_example['contract_id']}\")\n",
    "print(f\"   Function: {detailed_example['function_id']}\")\n",
    "print(f\"   Prediction: {detailed_example['predicted_label']} (correct: {detailed_example['correct']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850489ef",
   "metadata": {},
   "source": [
    "## Summary and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ab999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary of explainability results\n",
    "explainability_summary = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'model_path': str(model_path),\n",
    "    'configuration': {\n",
    "        'attention_layer': LAYER_TO_USE,\n",
    "        'average_heads': ATTENTION_HEAD_AVERAGE,\n",
    "        'top_k_tokens': TOP_K_TOKENS,\n",
    "        'min_attention_threshold': MIN_ATTENTION_THRESHOLD\n",
    "    },\n",
    "    'examples_analyzed': len(attention_results),\n",
    "    'visualizations_generated': len(visualization_files),\n",
    "    'attention_statistics': {\n",
    "        'max_attention_overall': float(attention_df['max_attention'].max()),\n",
    "        'mean_attention_overall': float(attention_df['max_attention'].mean()),\n",
    "        'attention_entropy_mean': float(attention_df['attention_entropy'].mean()),\n",
    "        'high_attention_tokens_mean': float(attention_df['num_high_attention_tokens'].mean())\n",
    "    },\n",
    "    'files_generated': {\n",
    "        'html_visualizations': visualization_files,\n",
    "        'attention_analysis_plot': str(attention_plot_path),\n",
    "        'token_importance_csv': str(token_importance_path),\n",
    "        'interactive_heatmap': str(heatmap_path)\n",
    "    },\n",
    "    'insights': {\n",
    "        'most_attended_tokens_overall': top_tokens_overall.head(10).index.tolist(),\n",
    "        'attention_patterns_by_vulnerability': dict(attention_df.groupby('vulnerability_type')['max_attention'].mean()),\n",
    "        'prediction_accuracy_analyzed': float(attention_df['prediction_correct'].mean())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "summary_path = RESULTS_DIR / 'explainability_summary.json'\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(explainability_summary, f, indent=2, default=str)\n",
    "\n",
    "print(\"üéâ ATTENTION VISUALIZATION COMPLETED!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìä Summary:\")\n",
    "print(f\"  ‚Ä¢ Analyzed {len(attention_results)} examples\")\n",
    "print(f\"  ‚Ä¢ Generated {len(visualization_files)} HTML visualizations\")\n",
    "print(f\"  ‚Ä¢ Created interactive attention heatmap\")\n",
    "print(f\"  ‚Ä¢ Analyzed {len(token_df)} token-attention pairs\")\n",
    "print(f\"\\nüîç Key Insights:\")\n",
    "print(f\"  ‚Ä¢ Average max attention: {attention_df['max_attention'].mean():.4f}\")\n",
    "print(f\"  ‚Ä¢ Most attended token: '{top_tokens_overall.index[0]}'\")\n",
    "print(f\"  ‚Ä¢ Prediction accuracy on analyzed examples: {attention_df['prediction_correct'].mean():.2%}\")\n",
    "print(f\"\\nüìÅ All results saved to: {RESULTS_DIR / 'visualizations'}\")\n",
    "print(f\"üíæ Summary saved to: {summary_path}\")\n",
    "\n",
    "# Display one example visualization in notebook\n",
    "if visualization_files:\n",
    "    print(f\"\\nüîç Sample visualization (first example):\")\n",
    "    sample_file = visualization_files[0]\n",
    "    print(f\"File: {Path(sample_file).name}\")\n",
    "    \n",
    "    # You can uncomment the following lines to display HTML in notebook\n",
    "    # with open(sample_file, 'r', encoding='utf-8') as f:\n",
    "    #     html_content = f.read()\n",
    "    # display(HTML(html_content))\n",
    "    \n",
    "print(\"\\n‚ú® Open the generated HTML files in a browser to view interactive attention visualizations!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
